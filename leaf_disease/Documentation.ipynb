{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6111d6d",
   "metadata": {},
   "source": [
    "# Leaf Disease Classification CNN Model\n",
    "\n",
    "---\n",
    "\n",
    "This is a ML model created by Keshav Ghai (An aspiring AI/ML dev).\n",
    "\n",
    "This is a **Convolutional Neural Network (CNN)** which classifies plant leaf diseases across multiple crop types. The model learns hierarchical visual features from leaf images to identify disease patterns, discoloration, spots, and other disease-specific indicators. Unlike previous models that worked with single-class classification, this model performs **multi-class classification** with a plant + disease mapping system. The training script **\"trainer.py\"** takes image data, preprocesses it, trains a CNN with 3 convolutional blocks, and generates visualizations.\n",
    "\n",
    "## What makes this different?\n",
    "\n",
    "Traditional disease identification requires domain expertise. This model automates the process by learning disease-specific visual patterns. It combines:\n",
    "- **Hierarchical feature extraction** through 3 CNN blocks (32→64→128 filters)\n",
    "- **Plant + Disease mapping** for interpretable, hierarchical predictions\n",
    "- **Multi-crop support** - identifies both the plant type and specific disease\n",
    "\n",
    "## Imports:-\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc3afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f5c3c2",
   "metadata": {},
   "source": [
    "## 0. Dataset Normalization (Data Preprocessing)\n",
    "---\n",
    "\n",
    "Before actually starting the model, we have to normalize the dataset. It is done through these steps:\n",
    "\n",
    "**Why normalize?** Raw leaf images come in different sizes, orientations, and lighting conditions. Normalization standardizes them so the model can process them consistently.\n",
    "\n",
    "### Normalization Steps:\n",
    "1. **Read images** using OpenCV from the dataset folder\n",
    "2. **Convert color space** from BGR (OpenCV's default) to RGB (standard format)\n",
    "3. **Resize to 256×256** - ensures all images have the same dimensions\n",
    "4. **Save normalized images** to a new clean directory\n",
    "\n",
    "The `normalization.py` script handles this automatically, creating a `normalized_dataset` folder with properly formatted images ready for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ad7b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization.py\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "DATASET_DIR = \"./tensorflow/leaf_disease/dataset\"\n",
    "OUTPUT_DIR = \"./tensorflow/leaf_disease/normalized_dataset\"\n",
    "TARGET_SIZE = (256, 256)\n",
    "\n",
    "def ensure_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def normalize_images():\n",
    "    ensure_dir(OUTPUT_DIR)\n",
    "    \n",
    "    # Create Train and Val directories\n",
    "    for split in ['Train', 'Val']:\n",
    "        for item in os.listdir(os.path.join(DATASET_DIR, split)):\n",
    "            input_path = os.path.join(DATASET_DIR, split, item)\n",
    "            output_path = os.path.join(OUTPUT_DIR, split, item)\n",
    "            ensure_dir(output_path)\n",
    "            \n",
    "            for img_name in os.listdir(input_path):\n",
    "                img_path = os.path.join(input_path, img_name)\n",
    "                img = cv2.imread(img_path)\n",
    "                \n",
    "                if img is None:\n",
    "                    continue\n",
    "                \n",
    "                # Convert BGR → RGB\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                # Resize to 256×256\n",
    "                img = cv2.resize(img, TARGET_SIZE)\n",
    "                \n",
    "                # Save normalized image\n",
    "                out_path = os.path.join(output_path, img_name)\n",
    "                cv2.imwrite(out_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    print(\"Normalization complete! All images resized to 256x256.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    normalize_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cbae17",
   "metadata": {},
   "source": [
    "## 1. Define Paths and Constants\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f0be06",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"./tensorflow/leaf_disease/normalized_dataset\"\n",
    "MODEL_SAVE_PATH = \"./Models/leaf_disease_model.keras\"\n",
    "CLASS_MAP_PATH = \"./tensorflow/leaf_disease/class_indices.json\"\n",
    "\n",
    "IMG_SIZE = (256, 256)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 13\n",
    "\n",
    "print(f\"Dataset directory: {DATASET_DIR}\")\n",
    "print(f\"Model will be saved to: {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5796eb63",
   "metadata": {},
   "source": [
    "## 2. Dataset Helper Function\n",
    "---\n",
    "\n",
    "Creating a helper function to clean disease names for display (converting underscores to spaces and proper capitalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0024dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_disease_name(raw):\n",
    "    \"\"\"Convert raw disease name to readable format.\"\"\"\n",
    "    name = raw.replace(\"_\", \" \")\n",
    "    name = re.sub(r\"\\s+\", \" \", name).strip()\n",
    "\n",
    "    tokens = name.split(\" \")\n",
    "    rebuilt = []\n",
    "    current = []\n",
    "\n",
    "    for token in tokens:\n",
    "        if not token:\n",
    "            continue\n",
    "        if token[0].isupper() and current:\n",
    "            rebuilt.append(\" \".join(current))\n",
    "            current = [token]\n",
    "        else:\n",
    "            current.append(token)\n",
    "\n",
    "    if current:\n",
    "        rebuilt.append(\" \".join(current))\n",
    "\n",
    "    final = \", \".join(rebuilt)\n",
    "    final = final.title()\n",
    "\n",
    "    final = re.sub(\n",
    "        r\"\\(([^)]+)\\)\",\n",
    "        lambda m: \"(\" + m.group(1).replace(\"_\", \" \").title() + \")\",\n",
    "        final\n",
    "    )\n",
    "\n",
    "    return final\n",
    "\n",
    "# Test the function\n",
    "print(clean_disease_name(\"Early_Blight\"))\n",
    "print(clean_disease_name(\"Late_Blight\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3f7a02",
   "metadata": {},
   "source": [
    "## 3. Load Training and Validation Datasets\n",
    "---\n",
    "\n",
    "> Images are loaded from directories using Keras' `image_dataset_from_directory()`. This function automatically handles:\n",
    "> - Reading images from subdirectories (each subdirectory = a class)\n",
    "> - Converting images to tensors\n",
    "> - Batching the data\n",
    "> - Integer label mode for multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4839ea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ensure consistent class ordering between Train and Val, compute class list once\n",
    "train_dir = os.path.join(DATASET_DIR, \"Train\")\n",
    "class_list = sorted([d for d in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, d))])\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    os.path.join(DATASET_DIR, \"Train\"),\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"int\",\n",
    "    class_names=class_list\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    os.path.join(DATASET_DIR, \"Val\"),\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"int\",\n",
    "    class_names=class_list\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "print(f\"Sample classes: {class_names[:5]}\")\n",
    "\n",
    "# Sanity check: ensure both datasets use the same class ordering\n",
    "assert train_ds.class_names == val_ds.class_names, \"Train/Val class ordering mismatch!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed15735",
   "metadata": {},
   "source": [
    "## 4. Build Class Mapping (Plant + Disease)\n",
    "---\n",
    "\n",
    "> Class names follow the format: `Plant___Disease`\n",
    "> We extract plant and disease, then save a JSON mapping for later inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047cfdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_class_map():\n",
    "    mapping = {}\n",
    "\n",
    "    for idx, cls in enumerate(class_names):\n",
    "        # Safely partition by delimiter to avoid ValueError\n",
    "        plant, sep, disease_raw = cls.partition(\"___\")\n",
    "        if sep == \"\":\n",
    "            # Missing delimiter - log and default disease_raw to empty\n",
    "            print(f\"Warning: class name '{cls}' missing '___' delimiter. Skipping detailed disease parsing.\")\n",
    "            disease_raw = \"\"\n",
    "\n",
    "        disease_clean = clean_disease_name(disease_raw) if disease_raw else \"\"\n",
    "\n",
    "        mapping[cls] = {\n",
    "            \"index\": idx,\n",
    "            \"plant\": plant,\n",
    "            \"disease_raw\": disease_raw,\n",
    "            \"disease\": disease_clean\n",
    "        }\n",
    "\n",
    "    with open(CLASS_MAP_PATH, \"w\") as f:\n",
    "        json.dump(mapping, f, indent=4)\n",
    "\n",
    "    return mapping\n",
    "\n",
    "class_map = build_class_map()\n",
    "\n",
    "print(f\"Sample mappings:\")\n",
    "for i, (key, val) in enumerate(list(class_map.items())[:3]):\n",
    "    print(f\"  {key}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b3cc17",
   "metadata": {},
   "source": [
    "## 5. Prefetch for Performance\n",
    "---\n",
    "\n",
    "> Prefetch optimizes data loading by preparing batches while the model trains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6961d452",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"Datasets prefetched for optimal performance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ababedf",
   "metadata": {},
   "source": [
    "## 6. Model Architecture\n",
    "---\n",
    "\n",
    "> The model uses 3 convolutional blocks that progressively extract and combine features:\n",
    "> - **Block 1 (32 filters)**: Detects low-level features (edges, textures)\n",
    "> - **Block 2 (64 filters)**: Combines features, detects patterns\n",
    "> - **Block 3 (128 filters)**: Learns complex disease-specific patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc09906",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3), name=\"input\"),\n",
    "    tf.keras.layers.Rescaling(1.0/255.0),\n",
    "    \n",
    "    # Block 1: 32 filters\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Block 2: 64 filters\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Block 3: 128 filters\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Dense layers\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(len(class_names), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efa8428",
   "metadata": {},
   "source": [
    "## 7. Train the Model\n",
    "---\n",
    "\n",
    "> The model is trained for 13 epochs with a batch size of 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fa4f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Ensure model save directory exists\n",
    "model_dir = os.path.dirname(MODEL_SAVE_PATH)\n",
    "if model_dir:\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "model.save(MODEL_SAVE_PATH)\n",
    "print(f\"Model saved to {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf5bcf0",
   "metadata": {},
   "source": [
    "## 8. Training Visualizations\n",
    "---\n",
    "\n",
    "### a. Loss Over Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a8aca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.title(\"Loss Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"./tensorflow/leaf_disease/loss_graph.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561cb8e0",
   "metadata": {},
   "source": [
    "### b. Accuracy Over Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24e578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Val Accuracy\")\n",
    "plt.title(\"Accuracy Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"./tensorflow/leaf_disease/accuracy_graph.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61f716e",
   "metadata": {},
   "source": [
    "### c. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad47dcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all validation predictions\n",
    "val_pred_raw = model.predict(val_ds)\n",
    "val_pred_classes = np.argmax(val_pred_raw, axis=1)\n",
    "\n",
    "# Get true labels\n",
    "val_labels = np.concatenate([y for x, y in val_ds])\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(val_labels, val_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=True)\n",
    "plt.title(\"Confusion Matrix - Leaf Disease Classification\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.savefig(\"./tensorflow/leaf_disease/confusion_matrix.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved: loss_graph.png, accuracy_graph.png, confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60cc40e",
   "metadata": {},
   "source": [
    "## 9. Interactive Testing\n",
    "---\n",
    "\n",
    "> Test the model on individual leaf images with plant + disease predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf2bdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reverse mapping for inference\n",
    "index_to_class = {v['index']: k for k, v in class_map.items()}\n",
    "\n",
    "print(\"\\nInteractive testing mode:\")\n",
    "print(\"(Run this cell and enter image paths to test the model)\\n\")\n",
    "\n",
    "while True:\n",
    "    img_path = input(\"Enter leaf image path (or 'quit'): \").strip()\n",
    "    \n",
    "    if img_path.lower() == \"quit\":\n",
    "        break\n",
    "    \n",
    "    if not os.path.exists(img_path):\n",
    "        print(\"File not found, try again.\\n\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Load and preprocess image\n",
    "        img = tf.keras.preprocessing.image.load_img(img_path, target_size=IMG_SIZE)\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img_batch = np.expand_dims(img_array, axis=0)\n",
    "        \n",
    "        # Make prediction\n",
    "        pred = model.predict(img_batch, verbose=0)[0]\n",
    "        class_id = np.argmax(pred)\n",
    "        class_name = index_to_class[class_id]\n",
    "        confidence = float(np.max(pred) * 100)\n",
    "        \n",
    "        # Extract info\n",
    "        plant = class_map[class_name]['plant']\n",
    "        disease = class_map[class_name]['disease']\n",
    "        \n",
    "        print(f\"\\nPrediction:\")\n",
    "        print(f\"  Plant: {plant}\")\n",
    "        print(f\"  Disease: {disease}\")\n",
    "        print(f\"  Confidence: {confidence:.2f}%\\n\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
