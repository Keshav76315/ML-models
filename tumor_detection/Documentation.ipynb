{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "334dcac9",
   "metadata": {},
   "source": [
    "# Brain Tumor Detection CNN Model\n",
    "\n",
    "---\n",
    "\n",
    "This is a ML model created by Keshav Ghai (An aspiring AI/ML dev).\n",
    "\n",
    "This is a **Convolutional Neural Network (CNN)** which detects and classifies brain tumors from MRI scan images. Unlike binary classification models, this is a **multi-class classifier** that can distinguish between different types of brain tumors. The training script **\"trainer.py\"** takes MRI image data, preprocesses it, trains a CNN with 3 convolutional layers, and generates visualizations for model performance analysis.\n",
    "\n",
    "## What makes this different?\n",
    "\n",
    "This model performs **multi-class classification** (typically 4 classes: no tumor, glioma, meningioma, pituitary). CNNs are ideal for medical imaging because they automatically learn to detect complex patterns in images—from simple edges to complex anatomical structures. The model helps radiologists by providing a second opinion on brain tumor classification from MRI scans.\n",
    "\n",
    "## Imports:-\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0b3761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2dc775",
   "metadata": {},
   "source": [
    "## 0. Dataset Normalization (Data Preprocessing)\n",
    "---\n",
    "\n",
    "Before training the model, the MRI dataset must be normalized. It is done through these steps:\n",
    "\n",
    "**Why normalize?** Medical images come from different scanners with different pixel value ranges. Normalization ensures consistency so the model can learn general patterns rather than scanner-specific artifacts.\n",
    "\n",
    "### Normalization Steps:\n",
    "1. **Read MRI images** from raw dataset folders\n",
    "2. **Convert to RGB** - standardize color format for consistency\n",
    "3. **Resize to 256×256** - ensures all images have the same dimensions for the model input\n",
    "4. **Organize into Train/Val/Test splits** - separate directories for training, validation, and testing\n",
    "5. **Save normalized images** to `normalized_dataset` with proper folder structure maintaining class labels\n",
    "\n",
    "The dataset structure should be:\n",
    "```\n",
    "normalized_dataset/\n",
    "├── Train/\n",
    "│   ├── glioma/\n",
    "│   ├── meningioma/\n",
    "│   ├── notumor/\n",
    "│   └── pituitary/\n",
    "└── Val/\n",
    "    ├── glioma/\n",
    "    ├── meningioma/\n",
    "    ├── notumor/\n",
    "    └── pituitary/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078cdd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# Paths for raw and normalized datasets\n",
    "RAW_DATASET = \"./tensorflow/tumor_detection/dataset\"\n",
    "OUTPUT_DATASET = \"./tensorflow/tumor_detection/normalized_dataset\"\n",
    "\n",
    "TARGET_SIZE = (256, 256)\n",
    "\n",
    "def ensure_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def process_split(split):\n",
    "    input_dir = os.path.join(RAW_DATASET, split)\n",
    "    output_dir = os.path.join(OUTPUT_DATASET, split)\n",
    "    ensure_dir(output_dir)\n",
    "\n",
    "    classes = os.listdir(input_dir)\n",
    "\n",
    "    for cls in classes:\n",
    "        cls_input = os.path.join(input_dir, cls)\n",
    "        cls_output = os.path.join(output_dir, cls)\n",
    "        ensure_dir(cls_output)\n",
    "\n",
    "        for img_name in os.listdir(cls_input):\n",
    "            img_path = os.path.join(cls_input, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, TARGET_SIZE)\n",
    "\n",
    "            out_path = os.path.join(cls_output, os.path.splitext(img_name)[0] + \".png\")\n",
    "            cv2.imwrite(out_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    print(f\"{split} split processed.\")\n",
    "\n",
    "def main():\n",
    "    process_split(\"Train\")\n",
    "    process_split(\"Val\")\n",
    "    print(\"Normalization complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265bf9ac",
   "metadata": {},
   "source": [
    "## 1. Define Paths and Constants\n",
    "---\n",
    "\n",
    "> These variables point to the normalized dataset directories and where to save the trained model and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a151c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to normalized dataset\n",
    "DATASET_DIR = \"./tensorflow/tumor_detection/normalized_dataset\"\n",
    "\n",
    "# Model output paths\n",
    "MODEL_SAVE_PATH = \"./Models/brain_tumor_model.keras\"\n",
    "CLASS_INDICES_PATH = \"./tensorflow/tumor_detection/class_indices.json\"\n",
    "\n",
    "# Directory for saving plots\n",
    "PLOT_DIR = \"./tensorflow/tumor_detection\"\n",
    "\n",
    "# Image and training settings\n",
    "IMG_SIZE = (256, 256)  # Height x Width of MRI images\n",
    "BATCH_SIZE = 32        # Number of images to process together\n",
    "\n",
    "print(f\"Dataset loaded from: {DATASET_DIR}\")\n",
    "print(f\"Model will be saved to: {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d3e346",
   "metadata": {},
   "source": [
    "## 2. Load Training and Validation Datasets\n",
    "---\n",
    "\n",
    "> TensorFlow's `image_dataset_from_directory` automatically loads images and infers class labels from folder names (e.g., \"glioma\", \"meningioma\", \"notumor\", \"pituitary\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c290168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    os.path.join(DATASET_DIR, \"Train\"),\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"int\"  # Integer labels for sparse categorical crossentropy\n",
    ")\n",
    "\n",
    "# Load validation data\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    os.path.join(DATASET_DIR, \"Val\"),\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"int\"\n",
    ")\n",
    "\n",
    "# Get class names from the dataset\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"Classes detected: {class_names}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# Save class index mapping for later use during inference\n",
    "with open(CLASS_INDICES_PATH, \"w\") as f:\n",
    "    json.dump({cls: i for i, cls in enumerate(class_names)}, f)\n",
    "\n",
    "print(f\"Class mapping saved to: {CLASS_INDICES_PATH}\")\n",
    "\n",
    "# Prefetch: Load next batch while current batch is being processed (optimization)\n",
    "train_ds = train_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"\\nDataset loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfd4450",
   "metadata": {},
   "source": [
    "## 3. Understanding the Multi-Class CNN Architecture\n",
    "---\n",
    "\n",
    "> This CNN learns to distinguish between 4 different tumor classes. It uses hierarchical feature extraction: early layers detect simple patterns (edges, textures in MRI), middle layers combine them (tissue structures), and later layers recognize high-level features (tumor characteristics).\n",
    "\n",
    "### Architecture Components:\n",
    "\n",
    "**Rescaling Layer**: Normalizes pixel values from [0, 255] to [0, 1] for better neural network learning.\n",
    "\n",
    "**Conv2D Layers**: Extract features from MRI images using filters. `Conv2D(32, (3,3))` means 32 filters of size 3×3 pixels.\n",
    "\n",
    "**MaxPooling2D**: Reduces spatial dimensions and computational cost while preserving important features.\n",
    "\n",
    "**Flatten**: Converts 2D feature maps into a 1D vector for dense layers.\n",
    "\n",
    "**Dense Layers**: Learn high-level patterns and relationships between extracted features.\n",
    "\n",
    "**Dropout(0.3)**: Randomly ignores 30% of neurons to prevent overfitting.\n",
    "\n",
    "**Output Layer**: Softmax activation with N neurons (one for each tumor class) for multi-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46371f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the multi-class CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    # Normalize pixel values\n",
    "    tf.keras.layers.Rescaling(1./255, input_shape=(*IMG_SIZE, 3)),\n",
    "\n",
    "    # First convolutional block: Extract low-level features\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "    # Second convolutional block: Combine and refine features\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "    # Third convolutional block: Learn complex patterns\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "    # Flatten and fully connected layers\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(8, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    # Multi-class output layer (softmax for probability distribution)\n",
    "    tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",  # Loss for integer-encoded multi-class labels\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fe764b",
   "metadata": {},
   "source": [
    "## 4. Training the Model\n",
    "---\n",
    "\n",
    "> The model learns by:\n",
    "1. Making predictions on training MRI images\n",
    "2. Computing loss between predictions and actual tumor classes\n",
    "3. Backpropagating error and adjusting weights\n",
    "4. Repeating for 12 epochs (passes through entire training dataset)\n",
    "\n",
    "Each epoch processes all batches of 32 images and updates model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a01236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_ds,                    # Training data with labels\n",
    "    validation_data=val_ds,      # Validation data for monitoring\n",
    "    epochs=12                    # Number of complete passes through dataset\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save(MODEL_SAVE_PATH)\n",
    "print(f\"\\nModel saved at: {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eb3d74",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model Performance\n",
    "---\n",
    "\n",
    "> We test the model on both training and validation data:\n",
    "- **Training Accuracy**: How well it learned from training data\n",
    "- **Validation Accuracy**: How well it generalizes to unseen data (more important)\n",
    "\n",
    "Large gap between training and validation accuracy indicates overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b9c691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on training set\n",
    "train_loss, train_acc = model.evaluate(train_ds)\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_loss, val_acc = model.evaluate(val_ds)\n",
    "\n",
    "print(f\"\\n=== Model Performance ===\")\n",
    "print(f\"Training Accuracy:   {train_acc * 100:.2f}%\")\n",
    "print(f\"Validation Accuracy: {val_acc * 100:.2f}%\")\n",
    "print(f\"\\nTraining Loss:   {train_loss:.4f}\")\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a292ae",
   "metadata": {},
   "source": [
    "## 6. Visualizations\n",
    "---\n",
    "\n",
    "> Graphs show model learning progress over epochs and prediction accuracy across all tumor classes.\n",
    "\n",
    "### a. Loss Over Epochs:-\n",
    "\n",
    "Lower loss is better. Both curves should decrease smoothly. If validation loss increases sharply, the model is overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec3aaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss graph\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.title(\"Loss Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(PLOT_DIR, \"loss_graph.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(\"Loss graph saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dace8a7a",
   "metadata": {},
   "source": [
    "### b. Accuracy Over Epochs:-\n",
    "\n",
    "Higher accuracy is better. A steeply rising curve indicates the model is learning well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c445b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy graph\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Val Accuracy\")\n",
    "plt.title(\"Accuracy Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(PLOT_DIR, \"accuracy_graph.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(\"Accuracy graph saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426b791d",
   "metadata": {},
   "source": [
    "### c. Confusion Matrix (Multi-Class):-\n",
    "\n",
    "Shows how the model classifies each tumor type:\n",
    "- **Diagonal values**: Correct predictions for each class\n",
    "- **Off-diagonal values**: Misclassifications (which classes get confused with each other)\n",
    "\n",
    "Ideally, high diagonal values and low off-diagonal values indicate good performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490d3ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix on validation set\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# Predict on all validation batches\n",
    "for images, labels in val_ds:\n",
    "    preds = model.predict(images, verbose=0)\n",
    "    preds = np.argmax(preds, axis=1)  # Get class with highest probability\n",
    "\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(preds)\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot as heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", \n",
    "            xticklabels=class_names, \n",
    "            yticklabels=class_names,\n",
    "            cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix (Validation Set)\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.savefig(os.path.join(PLOT_DIR, \"confusion_matrix.png\"), bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"Confusion matrix saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66536847",
   "metadata": {},
   "source": [
    "## 7. Interactive Testing Mode\n",
    "---\n",
    "\n",
    "> Test the trained model on any MRI image. The model will:\n",
    "1. Read and preprocess the image (resize to 256×256, normalize)\n",
    "2. Make a prediction using the trained CNN\n",
    "3. Output the tumor class and confidence score\n",
    "4. Provide clinical interpretation (Tumor Present: YES/NO)\n",
    "\n",
    "The confidence score (0-100%) indicates how certain the model is about its prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e773dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nInteractive Testing Mode\")\n",
    "print(f\"Classes available: {class_names}\")\n",
    "print(\"Type an image path to test, or 'quit' to exit.\\n\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"Image path: \").strip()\n",
    "\n",
    "    if user_input.lower() == \"quit\":\n",
    "        print(\"Exiting interactive mode.\")\n",
    "        break\n",
    "\n",
    "    if not os.path.exists(user_input):\n",
    "        print(\"File not found. Try again.\\n\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Load and preprocess image\n",
    "        img = tf.keras.preprocessing.image.load_img(user_input, target_size=IMG_SIZE)\n",
    "        img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "        img = img / 255.0  # Normalize\n",
    "\n",
    "        # Make prediction\n",
    "        preds = model.predict(img, verbose=0)\n",
    "        class_id = np.argmax(preds[0])\n",
    "        class_name = class_names[class_id]\n",
    "        confidence = float(np.max(preds[0]) * 100)\n",
    "\n",
    "        print(f\"\\nPredicted Class: {class_name}\")\n",
    "        print(f\"Confidence: {confidence:.2f}%\")\n",
    "\n",
    "        # Clinical interpretation\n",
    "        if class_name == \"notumor\":\n",
    "            print(\"Clinical: Tumor Present - NO\")\n",
    "        else:\n",
    "            print(f\"Clinical: Tumor Present - YES ({class_name.upper()})\")\n",
    "        \n",
    "        # Show all class probabilities\n",
    "        print(\"\\nAll Class Probabilities:\")\n",
    "        for i, cls in enumerate(class_names):\n",
    "            print(f\"  {cls}: {preds[0][i]*100:.2f}%\")\n",
    "        print()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
