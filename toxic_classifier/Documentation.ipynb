{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc10b865",
   "metadata": {},
   "source": [
    "# Toxic Comments Classifier Model\n",
    "\n",
    "---\n",
    "\n",
    "This is a ML model created by Keshav Ghai (An aspiring AI/ML dev).\n",
    "\n",
    "This is a **Bidirectional LSTM (BiLSTM) neural network** which classifies online comments into **6 toxicity categories**: toxic, severe toxic, obscene, threat, insult, and identity hate. Unlike previous models that performed single-class classification, this model uses **multi-label classification** - meaning a single comment can be tagged with multiple toxicity types simultaneously. The training script **\"trainer.py\"** takes comment data from CSV files, tokenizes the text, trains a BiLSTM with word embeddings, and generates visualizations.\n",
    "\n",
    "## What makes this different?\n",
    "\n",
    "Online content moderation requires understanding nuanced language and context. This model:\n",
    "- Uses **bidirectional LSTM** to understand context from both directions (left and right)\n",
    "- Performs **multi-label classification** with sigmoid activation (not multi-class with softmax)\n",
    "- Handles **6 independent toxicity types** simultaneously with 0.5 confidence threshold\n",
    "- Works with **variable-length text** through padding\n",
    "\n",
    "## Imports:-\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0616989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea68480f",
   "metadata": {},
   "source": [
    "## 1. Define Paths and Constants\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3298468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"./tensorflow/toxic_classifier/dataset/\"\n",
    "MODEL_SAVE_PATH = \"./Models/toxic_model.keras\"\n",
    "TOKENIZER_SAVE_PATH = \"./tensorflow/toxic_classifier/toxic_tokenizer.json\"\n",
    "\n",
    "LABELS = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "MAX_VOCAB = 20000\n",
    "MAX_LEN = 256\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "\n",
    "print(f\"Toxicity labels: {LABELS}\")\n",
    "print(f\"Model will be saved to: {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad8661d",
   "metadata": {},
   "source": [
    "## 2. Load Training and Validation Data\n",
    "---\n",
    "\n",
    "> Data is loaded from CSV files provided by the Kaggle Toxic Comments dataset.\n",
    "> - **train.csv**: Comment text with 6 binary labels\n",
    "> - **test.csv**: Comment text for testing\n",
    "> - **test_labels.csv**: Labels for test comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9877b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_df = pd.read_csv(BASE_DIR + \"train.csv\")\n",
    "test_df = pd.read_csv(BASE_DIR + \"test.csv\")\n",
    "test_labels_df = pd.read_csv(BASE_DIR + \"test_labels.csv\")\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "print(\"Test labels shape:\", test_labels_df.shape)\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample training data:\")\n",
    "print(train_df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23adc5e7",
   "metadata": {},
   "source": [
    "## 3. Clean and Prepare Validation Data\n",
    "---\n",
    "\n",
    "> Some test labels have -1 values (indicating missing data). We remove these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe9267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with -1 (missing labels)\n",
    "test_labels_df = test_labels_df[test_labels_df[LABELS].min(axis=1) >= 0]\n",
    "\n",
    "# Merge test comments with their labels\n",
    "val_df = test_df.merge(test_labels_df, on=\"id\")\n",
    "\n",
    "print(f\"Validation usable rows: {val_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf505ed",
   "metadata": {},
   "source": [
    "## 4. Extract Text and Labels\n",
    "---\n",
    "\n",
    "> Separate text and labels into arrays for model training.\n",
    "> **Important**: Labels are already binary (0/1) for each toxicity type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ce2835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "X_train = train_df[\"comment_text\"].astype(str).tolist()\n",
    "y_train = train_df[LABELS].astype(\"float32\").values\n",
    "\n",
    "# Validation data\n",
    "X_val = val_df[\"comment_text\"].astype(str).tolist()\n",
    "y_val = val_df[LABELS].astype(\"float32\").values\n",
    "\n",
    "print(f\"Train samples: {len(X_train)}\")\n",
    "print(f\"Val samples: {len(X_val)}\")\n",
    "print(f\"Train label shape: {y_train.shape}\")\n",
    "print(f\"Val label shape: {y_val.shape}\")\n",
    "\n",
    "# Show label distribution\n",
    "print(\"\\nLabel distribution (train):\")\n",
    "for i, label in enumerate(LABELS):\n",
    "    count = np.sum(y_train[:, i])\n",
    "    pct = (count / y_train.shape[0]) * 100\n",
    "    print(f\"  {label}: {count} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48502135",
   "metadata": {},
   "source": [
    "## 5. Tokenize and Pad Text\n",
    "---\n",
    "\n",
    "> Comments are converted to sequences of integers, then padded to a fixed length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba39ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokenizer\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    num_words=MAX_VOCAB,\n",
    "    oov_token=\"<OOV>\"\n",
    ")\n",
    "\n",
    "# Fit on training text\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Save tokenizer (tokenizer.to_json() already returns a JSON string)\n",
    "with open(TOKENIZER_SAVE_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(tokenizer.to_json())\n",
    "\n",
    "print(f\"Tokenizer saved. Vocabulary size: {len(tokenizer.word_index)}\")\n",
    "\n",
    "# Convert to sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "# Pad sequences\n",
    "X_train_pad = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    X_train_seq, maxlen=MAX_LEN, padding=\"post\"\n",
    ")\n",
    "X_val_pad = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    X_val_seq, maxlen=MAX_LEN, padding=\"post\"\n",
    ")\n",
    "\n",
    "print(f\"Padded train shape: {X_train_pad.shape}\")\n",
    "print(f\"Padded val shape: {X_val_pad.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6ae885",
   "metadata": {},
   "source": [
    "## 6. Model Architecture\n",
    "---\n",
    "\n",
    "> This model uses **multi-label classification** with:\n",
    "> - **Embedding layer**: Converts token indices to dense vectors (8-dimensional)\n",
    "> - **Bidirectional LSTM**: Processes text in both directions (8 units)\n",
    "> - **Dense layers**: With dropout for regularization\n",
    "> - **Output**: 6 neurons with sigmoid activation (not softmax!) for independent binary predictions\n",
    "> - **Loss**: Binary crossentropy (not categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc69affb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(MAX_LEN,), dtype=\"int32\"),\n",
    "    tf.keras.layers.Embedding(MAX_VOCAB, 8),  # 8-dim word embeddings\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(8)),  # BiLSTM\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(len(LABELS), activation=\"sigmoid\")  # Multi-label: sigmoid\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",  # Multi-label: binary crossentropy\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dd8102",
   "metadata": {},
   "source": [
    "## 7. Train the Model\n",
    "---\n",
    "\n",
    "> Training with 32 batch size. (For full training, use more epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fb8195",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train_pad, y_train,\n",
    "    validation_data=(X_val_pad, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.save(MODEL_SAVE_PATH)\n",
    "print(f\"Model saved to {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f41602",
   "metadata": {},
   "source": [
    "## 8. Training Visualizations\n",
    "---\n",
    "\n",
    "### a. Loss Over Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0ac289",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.title(\"Loss Over Epochs (Binary Crossentropy)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"./tensorflow/toxic_classifier/loss_graph.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319aab97",
   "metadata": {},
   "source": [
    "### b. Accuracy Over Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dbb78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Val Accuracy\")\n",
    "plt.title(\"Accuracy Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"./tensorflow/toxic_classifier/accuracy_graph.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a75f72",
   "metadata": {},
   "source": [
    "### c. Per-Label Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88f22aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "y_val_pred = model.predict(X_val_pad, verbose=0)\n",
    "y_val_pred_binary = (y_val_pred > 0.5).astype(int)  # Apply 0.5 threshold\n",
    "\n",
    "# Create subplots for each label\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, label in enumerate(LABELS):\n",
    "    cm = confusion_matrix(y_val[:, i], y_val_pred_binary[:, i])\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axes[i],\n",
    "                xticklabels=[\"Not \" + label, label],\n",
    "                yticklabels=[\"Not \" + label, label])\n",
    "    axes[i].set_title(f\"Confusion Matrix: {label.replace('_', ' ').title()}\")\n",
    "    axes[i].set_ylabel(\"True\")\n",
    "    axes[i].set_xlabel(\"Predicted\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./tensorflow/toxic_classifier/confusion_matrix.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved confusion matrices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3497770c",
   "metadata": {},
   "source": [
    "## 9. Per-Label Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501ac587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"Per-Label Performance (Threshold = 0.5):\\n\")\n",
    "print(f\"{'Label':<20} {'Precision':<12} {'Recall':<12} {'F1-Score':<12}\")\n",
    "print(\"-\" * 56)\n",
    "\n",
    "for i, label in enumerate(LABELS):\n",
    "    precision = precision_score(y_val[:, i], y_val_pred_binary[:, i], zero_division=0)\n",
    "    recall = recall_score(y_val[:, i], y_val_pred_binary[:, i], zero_division=0)\n",
    "    f1 = f1_score(y_val[:, i], y_val_pred_binary[:, i], zero_division=0)\n",
    "    \n",
    "    print(f\"{label:<20} {precision:<12.4f} {recall:<12.4f} {f1:<12.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44026c53",
   "metadata": {},
   "source": [
    "## 10. Interactive Testing\n",
    "---\n",
    "\n",
    "> Test the model on custom comments with multi-label toxicity detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1fc176",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nInteractive testing mode:\")\n",
    "print(f\"Toxicity labels: {LABELS}\")\n",
    "print(\"(Run this cell and enter comments to test the model)\\n\")\n",
    "\n",
    "while True:\n",
    "    comment = input(\"Enter a comment (or 'quit'): \").strip()\n",
    "    \n",
    "    if comment.lower() == \"quit\":\n",
    "        break\n",
    "    \n",
    "    if not comment:\n",
    "        print(\"Please enter a non-empty comment.\\n\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Tokenize and pad\n",
    "        seq = tokenizer.texts_to_sequences([comment])\n",
    "        pad = tf.keras.preprocessing.sequence.pad_sequences(seq, maxlen=MAX_LEN, padding=\"post\")\n",
    "        \n",
    "        # Predict\n",
    "        pred = model.predict(pad, verbose=0)[0]\n",
    "        \n",
    "        # Get detected toxicity types (threshold > 0.5)\n",
    "        detected = []\n",
    "        for i, label in enumerate(LABELS):\n",
    "            if pred[i] > 0.5:\n",
    "                detected.append((label, pred[i] * 100))\n",
    "        \n",
    "        if detected:\n",
    "            print(\"\\nToxicity Detected:\")\n",
    "            for label, conf in sorted(detected, key=lambda x: x[1], reverse=True):\n",
    "                print(f\"  {label}: {conf:.2f}%\")\n",
    "        else:\n",
    "            print(\"\\nNo toxicity detected.\")\n",
    "        \n",
    "        print(\"\\nAll Probabilities:\")\n",
    "        for label, prob in zip(LABELS, pred):\n",
    "            print(f\"  {label}: {prob*100:.2f}%\")\n",
    "        print()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
