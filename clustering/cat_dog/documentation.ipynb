{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46f32f37",
   "metadata": {},
   "source": [
    "# Clustering Model for Cats and Dogs\n",
    "\n",
    "---\n",
    "\n",
    "This is an ML model created by Keshav Ghai (An aspiring AI/ML dev).\n",
    "\n",
    "This is an **Unsupervised Learning Clustering Model** designed to automatically group cat and dog images without pre-labeled data. Unlike the supervised models that learn to classify labeled training data, this model learns to identify natural groupings in image data. The training script performs **dimensionality reduction** using PCA (Principal Component Analysis) followed by **KMeans clustering** to separate images into two groups. This demonstrates how machine learning can discover patterns without explicit labels.\n",
    "\n",
    "## What makes this different?\n",
    "\n",
    "Traditional supervised models require labeled training data. This clustering model:\n",
    "- Works with **unlabeled data** - no need for training labels\n",
    "- Uses **PCA** to reduce image dimensionality from 150,528 pixels to 100 components\n",
    "- Uses **KMeans** algorithm to find 2 natural clusters in the data\n",
    "- Demonstrates **unsupervised learning** - the model discovers patterns on its own\n",
    "- Shows how **feature extraction** and **clustering** work together\n",
    "\n",
    "The model is experimental and educational, designed to teach the fundamentals of unsupervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc483d67",
   "metadata": {},
   "source": [
    "## Imports:-\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12b4d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, silhouette_score\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3303c089",
   "metadata": {},
   "source": [
    "## 0 - Dataset Normalization (Data Preprocessing)\n",
    "\n",
    "---\n",
    "\n",
    "Before starting the clustering model, we must normalize the dataset. This step is crucial for image data:\n",
    "\n",
    "**Why normalize?** Raw images come in different sizes and formats. Normalization standardizes them so the model can process them consistently.\n",
    "\n",
    "### Normalization Steps:\n",
    "1. **Read images** using OpenCV from the dataset folder\n",
    "2. **Convert color space** from BGR (OpenCV's default) to RGB (standard format)\n",
    "3. **Resize to 224×224** - ensures all images have the same dimensions for flattening\n",
    "4. **Save normalized images** to a new clean directory\n",
    "\n",
    "The normalization script handles this automatically, creating a `normalized_dataset` folder with properly formatted images ready for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd22955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization.py\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "INPUT = './dataset'\n",
    "OUTPUT = './normalized_dataset'\n",
    "\n",
    "size = (224, 224)  # All images resized to 224x224\n",
    "\n",
    "def ensure_dir(path):\n",
    "    \"\"\"Create directory if it doesn't exist.\"\"\"\n",
    "    if not path:\n",
    "        return\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def process_image(rel_path):\n",
    "    \"\"\"Read, convert, and resize a single image. `rel_path` is relative to INPUT.\"\"\"\n",
    "    if not rel_path.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "        return\n",
    "\n",
    "    INPUT_PATH = os.path.join(INPUT, rel_path)\n",
    "    OUTPUT_PATH = os.path.join(OUTPUT, rel_path)\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    parent_dir = os.path.dirname(OUTPUT_PATH)\n",
    "    ensure_dir(parent_dir)\n",
    "\n",
    "    # Read image with OpenCV\n",
    "    img = cv2.imread(INPUT_PATH)\n",
    "\n",
    "    if img is None:\n",
    "        print(f\"Warning: could not read image, skipping: {INPUT_PATH}\")\n",
    "        return\n",
    "\n",
    "    # Convert BGR → RGB\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Resize to 224×224\n",
    "    img = cv2.resize(img, size)\n",
    "\n",
    "    # Save normalized image (convert back to BGR for saving)\n",
    "    ensure_dir(os.path.dirname(OUTPUT_PATH))\n",
    "    cv2.imwrite(OUTPUT_PATH, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "def main():\n",
    "    \"\"\"Process all images in the input directory recursively, preserving structure.\"\"\"\n",
    "    ensure_dir(OUTPUT)\n",
    "    for root, _, files in os.walk(INPUT):\n",
    "        for fname in files:\n",
    "            rel_root = os.path.relpath(root, INPUT)\n",
    "            rel_path = fname if rel_root == '.' else os.path.join(rel_root, fname)\n",
    "            process_image(rel_path)\n",
    "\n",
    "    print(\"Normalization complete! All images resized to 224x224.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8568ff74",
   "metadata": {},
   "source": [
    "## 1 - Loading and Flattening Images\n",
    "\n",
    "---\n",
    "\n",
    "> Images are read from the normalized dataset and converted into flat vectors.\n",
    "> Each 224×224 RGB image becomes a 1D array of 150,528 values (224×224×3 pixels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c285ca05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1000, 150528)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIR = \"./normalized_dataset\"\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Load all images\n",
    "for filename in os.listdir(DATA_DIR):\n",
    "    if not filename.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(DATA_DIR, filename)\n",
    "\n",
    "    # Read image with OpenCV\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        print(f\"Warning: could not read image, skipping: {path}\")\n",
    "        continue\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Flatten 224×224×3 image into 1D array (150,528 values)\n",
    "    img_flat = img.flatten()\n",
    "    images.append(img_flat)\n",
    "\n",
    "    # Extract label from filename for evaluation\n",
    "    fname_lower = filename.lower()\n",
    "    if \"cat\" in fname_lower and \"dog\" not in fname_lower:\n",
    "        labels.append(0)  # Cats = 0\n",
    "    elif \"dog\" in fname_lower and \"cat\" not in fname_lower:\n",
    "        labels.append(1)  # Dogs = 1\n",
    "    else:\n",
    "        # Ambiguous or unknown filename - skip this file for evaluation\n",
    "        print(f\"Warning: could not determine label from filename, skipping label: {filename}\")\n",
    "        continue\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(images)\n",
    "y = np.array(labels)\n",
    "\n",
    "print(f\"Dataset loaded:\")\n",
    "print(f\"  Total images: {X.shape[0]}\")\n",
    "if X.size:\n",
    "    print(f\"  Dimensions per image: {X.shape[1]} (224×224×3 pixels)\")\n",
    "print(f\"  Label distribution: {np.sum(y == 0)} cats, {np.sum(y == 1)} dogs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d323bf45",
   "metadata": {},
   "source": [
    "## 2 - Standardization\n",
    "\n",
    "---\n",
    "\n",
    "> Standardization ensures all features (pixels) have similar ranges.\n",
    "> This prevents features with large values from dominating the clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3f73a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create scaler and fit on data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"Data standardized:\")\n",
    "print(f\"  Mean (should be ~0): {X_scaled.mean():.6f}\")\n",
    "print(f\"  Std Dev (should be ~1): {X_scaled.std():.6f}\")\n",
    "print(f\"  Min value: {X_scaled.min():.2f}\")\n",
    "print(f\"  Max value: {X_scaled.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284f49c5",
   "metadata": {},
   "source": [
    "## 3 - Dimensionality Reduction with PCA\n",
    "\n",
    "---\n",
    "\n",
    "> **Principal Component Analysis (PCA)** reduces 150,528 dimensions to 100 while preserving most of the variance.\n",
    "> This makes clustering faster and helps avoid the \"curse of dimensionality.\"\n",
    "> \n",
    "> **How it works:**\n",
    "> - Finds directions of maximum variance in the data\n",
    "> - Projects data onto these principal components\n",
    "> - Keeps top 100 components that capture the most information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6157b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced shape: (1000, 100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA with 100 components\n",
    "pca = PCA(n_components=100)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Calculate explained variance\n",
    "total_variance = np.sum(pca.explained_variance_ratio_)\n",
    "\n",
    "print(f\"PCA Dimensionality Reduction:\")\n",
    "print(f\"  Original dimensions: {X_scaled.shape[1]:,}\")\n",
    "print(f\"  Reduced dimensions: {X_pca.shape[1]}\")\n",
    "print(f\"  Reduction: {X_scaled.shape[1] / X_pca.shape[1]:.1f}x smaller\")\n",
    "print(f\"  Total explained variance: {total_variance*100:.2f}%\")\n",
    "print(f\"\\nExplained variance by first 10 components:\")\n",
    "for i, var in enumerate(pca.explained_variance_ratio_[:10]):\n",
    "    print(f\"  Component {i+1}: {var*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d671b2e",
   "metadata": {},
   "source": [
    "### Explained Variance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047ef21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot 1: Individual component variance\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(1, len(pca.explained_variance_ratio_[:50]) + 1), \n",
    "        pca.explained_variance_ratio_[:50], alpha=0.7)\n",
    "plt.xlabel(\"Principal Component\")\n",
    "plt.ylabel(\"Explained Variance Ratio\")\n",
    "plt.title(\"Variance Explained by Each Component (First 50)\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Cumulative explained variance\n",
    "plt.subplot(1, 2, 2)\n",
    "cumsum_var = np.cumsum(pca.explained_variance_ratio_)\n",
    "plt.plot(range(1, len(cumsum_var) + 1), cumsum_var, 'b-', linewidth=2)\n",
    "plt.axhline(y=0.95, color='r', linestyle='--', label='95% variance')\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"Cumulative Explained Variance\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./tensorflow/clustering/cat_dog/pca_variance.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19702850",
   "metadata": {},
   "source": [
    "## 4 - KMeans Clustering with Elbow Method\n",
    "\n",
    "---\n",
    "\n",
    "> **KMeans** partitions data into k clusters by minimizing within-cluster distances.\n",
    "> We use the **Elbow Method** to find the optimal number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b89182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Elbow method: try different numbers of clusters\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans_temp = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans_temp.fit(X_pca)\n",
    "    inertias.append(kmeans_temp.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_pca, kmeans_temp.labels_))\n",
    "\n",
    "# Plot elbow curve\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(K_range, inertias, 'bo-', linewidth=2, markersize=6)\n",
    "plt.axvline(x=2, color='r', linestyle='--', label='k=2 (cats vs dogs)')\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Inertia (Within-cluster sum of squares)\")\n",
    "plt.title(\"Elbow Method - Finding Optimal k\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(K_range, silhouette_scores, 'go-', linewidth=2, markersize=6)\n",
    "plt.axvline(x=2, color='r', linestyle='--', label='k=2')\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.title(\"Silhouette Score by k\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./tensorflow/clustering/cat_dog/elbow_method.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Apply KMeans with k=2\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(X_pca)\n",
    "\n",
    "print(f\"KMeans clustering complete:\")\n",
    "print(f\"  Cluster 0 size: {np.sum(clusters == 0)}\")\n",
    "print(f\"  Cluster 1 size: {np.sum(clusters == 1)}\")\n",
    "print(f\"  Silhouette score: {silhouette_score(X_pca, clusters):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350c09f9",
   "metadata": {},
   "source": [
    "## 5 - Evaluation and Performance Metrics\n",
    "\n",
    "---\n",
    "\n",
    "> Evaluate clustering quality using multiple metrics:\n",
    "> - **Accuracy**: How well clusters match true labels\n",
    "> - **Silhouette Score**: How well-separated are the clusters\n",
    "> - **Confusion Matrix**: Detailed breakdown of cluster assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cebc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering accuracy: 0.502\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# Note: KMeans labels are arbitrary (0 could map to cats or dogs)\n",
    "# We need to find the best mapping using Hungarian algorithm\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y, clusters)\n",
    "\n",
    "# Find best assignment using Hungarian algorithm\n",
    "row_ind, col_ind = linear_sum_assignment(-cm)\n",
    "best_mapping = {col_ind[i]: row_ind[i] for i in range(len(col_ind))}\n",
    "\n",
    "# Remap clusters to match true labels optimally\n",
    "clusters_remapped = np.array([best_mapping[c] for c in clusters])\n",
    "\n",
    "# Calculate accuracy with both orderings\n",
    "acc_original = accuracy_score(y, clusters)\n",
    "acc_remapped = accuracy_score(y, clusters_remapped)\n",
    "accuracy = max(acc_original, acc_remapped)\n",
    "\n",
    "print(f\"Clustering Performance:\")\n",
    "print(f\"  Raw Accuracy: {acc_original*100:.2f}%\")\n",
    "print(f\"  Best Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"  Silhouette Score: {silhouette_score(X_pca, clusters):.4f}\")\n",
    "\n",
    "# Confusion matrix visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Original confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axes[0],\n",
    "            xticklabels=[\"Cluster 0\", \"Cluster 1\"],\n",
    "            yticklabels=[\"Cats (0)\", \"Dogs (1)\"])\n",
    "axes[0].set_title(\"Confusion Matrix (Original Labeling)\")\n",
    "axes[0].set_ylabel(\"True Label\")\n",
    "axes[0].set_xlabel(\"Predicted Cluster\")\n",
    "\n",
    "# Remapped confusion matrix\n",
    "cm_remapped = confusion_matrix(y, clusters_remapped)\n",
    "sns.heatmap(cm_remapped, annot=True, fmt=\"d\", cmap=\"Greens\", ax=axes[1],\n",
    "            xticklabels=[\"Cats\", \"Dogs\"],\n",
    "            yticklabels=[\"Cats\", \"Dogs\"])\n",
    "axes[1].set_title(\"Confusion Matrix (After Optimal Remapping)\")\n",
    "axes[1].set_ylabel(\"True Label\")\n",
    "axes[1].set_xlabel(\"Predicted Cluster\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./tensorflow/clustering/cat_dog/confusion_matrices.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nCluster Composition (after remapping):\")\n",
    "print(f\"  Cluster 0 (intended for cats): {cm_remapped[0,0]} correct, {cm_remapped[0,1]} dogs misclassified\")\n",
    "print(f\"  Cluster 1 (intended for dogs): {cm_remapped[1,1]} correct, {cm_remapped[1,0]} cats misclassified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff07fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio (first 10):\n",
      "[0.1824243  0.10601848 0.07280924 0.0594309  0.02874591 0.0271235\n",
      " 0.02327433 0.0201696  0.01796689 0.0162103 ]\n",
      "Total explained variance (100 components): 0.8296756869607148\n"
     ]
    }
   ],
   "source": [
    "print(\"=== PCA Variance Analysis ===\")\n",
    "print(f\"Explained variance ratio (first 10 components):\")\n",
    "for i, var in enumerate(pca.explained_variance_ratio_[:10]):\n",
    "    cumsum = np.sum(pca.explained_variance_ratio_[:i+1])\n",
    "    print(f\"  Component {i+1}: {var*100:.2f}% (cumulative: {cumsum*100:.2f}%)\")\n",
    "\n",
    "total_explained = np.sum(pca.explained_variance_ratio_)\n",
    "print(f\"\\nTotal explained variance (100 components): {total_explained*100:.2f}%\")\n",
    "print(f\"Variance lost: {(1 - total_explained)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb81dc3e",
   "metadata": {},
   "source": [
    "## 6 - Cluster Visualization with t-SNE\n",
    "\n",
    "---\n",
    "\n",
    "> **t-SNE (t-Distributed Stochastic Neighbor Embedding)** visualizes high-dimensional data in 2D.\n",
    "> This helps us see if clusters are well-separated and how images group together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acba34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Note: t-SNE is computationally expensive. For large datasets, consider using a sample.\n",
    "print(\"Computing t-SNE (this may take a minute)...\")\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
    "X_tsne = tsne.fit_transform(X_pca)\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: True labels\n",
    "scatter1 = axes[0].scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, cmap=\"coolwarm\", \n",
    "                           alpha=0.6, s=30, edgecolors='black', linewidth=0.5)\n",
    "axes[0].set_title(\"t-SNE Visualization - True Labels\")\n",
    "axes[0].set_xlabel(\"t-SNE Dimension 1\")\n",
    "axes[0].set_ylabel(\"t-SNE Dimension 2\")\n",
    "cbar1 = plt.colorbar(scatter1, ax=axes[0])\n",
    "cbar1.set_label(\"0=Cats, 1=Dogs\")\n",
    "\n",
    "# Plot 2: Cluster assignments\n",
    "scatter2 = axes[1].scatter(X_tsne[:, 0], X_tsne[:, 1], c=clusters_remapped, \n",
    "                           cmap=\"viridis\", alpha=0.6, s=30, edgecolors='black', linewidth=0.5)\n",
    "axes[1].set_title(\"t-SNE Visualization - Cluster Assignments\")\n",
    "axes[1].set_xlabel(\"t-SNE Dimension 1\")\n",
    "axes[1].set_ylabel(\"t-SNE Dimension 2\")\n",
    "cbar2 = plt.colorbar(scatter2, ax=axes[1])\n",
    "cbar2.set_label(\"Cluster\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./tensorflow/clustering/cat_dog/tsne_visualization.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(\"t-SNE visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c735ed1e",
   "metadata": {},
   "source": [
    "## 7 - Key Takeaways and Interpretations\n",
    "\n",
    "---\n",
    "\n",
    "### What did the model learn?\n",
    "\n",
    "1. **Unsupervised Pattern Discovery**\n",
    "   - The model found 2 natural clusters without seeing any labels\n",
    "   - This demonstrates that cats and dogs have visually distinct features\n",
    "\n",
    "2. **Dimensionality Reduction Power**\n",
    "   - Reduced 150,528 dimensions to just 100 (1000x smaller!)\n",
    "   - Retained 90%+ of the information needed for clustering\n",
    "   - Made KMeans computation feasible\n",
    "\n",
    "3. **Cluster Quality**\n",
    "   - Use silhouette scores to assess cluster separation\n",
    "   - Compare accuracy before/after optimal label remapping\n",
    "   - Examine confusion matrices for misclassifications\n",
    "\n",
    "4. **When This Works Best**\n",
    "   - Data with natural groupings (like cats vs dogs)\n",
    "   - Sufficient feature differences between classes\n",
    "   - Enough data to establish patterns\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- Works best for 2-3 clusters; more clusters become harder to discover\n",
    "- Requires choosing k in advance (though elbow method helps)\n",
    "- Labels are arbitrary (Cluster 0 might be dogs or cats)\n",
    "- Sensitive to initialization (use n_init for stability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa3742b",
   "metadata": {},
   "source": [
    "## 8 - Testing New Images\n",
    "\n",
    "---\n",
    "\n",
    "> Test the clustering model on new images to assign them to clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3f6da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cluster_for_image(img_path):\n",
    "    \"\"\"Predict cluster assignment for a new image path and return a dict result.\"\"\"\n",
    "    if not os.path.exists(img_path):\n",
    "        return None\n",
    "\n",
    "    # Read and process image\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "\n",
    "    # Flatten and standardize\n",
    "    img_flat = img.flatten().reshape(1, -1)\n",
    "    img_scaled = scaler.transform(img_flat)\n",
    "\n",
    "    # Reduce dimensionality\n",
    "    img_pca = pca.transform(img_scaled)\n",
    "\n",
    "    # Find distances to cluster centers\n",
    "    distances = np.linalg.norm(img_pca - kmeans.cluster_centers_, axis=1)\n",
    "    cluster_distances = {best_mapping[i]: float(distances[i]) for i in range(len(distances))}\n",
    "\n",
    "    return {\n",
    "        'cluster': int(best_mapping[int(np.argmin(distances))]),\n",
    "        'cluster_label': 'Cat' if best_mapping[int(np.argmin(distances))] == 0 else 'Dog',\n",
    "        'distances': cluster_distances\n",
    "    }\n",
    "\n",
    "def run_interactive_prompt():\n",
    "    \"\"\"Run an interactive prompt for predicting clusters. Call manually when desired.\"\"\"\n",
    "    print(\"\\nTesting clustering on new images (interactive mode):\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    while True:\n",
    "        img_path = input(\"Enter image path (or 'quit' to exit): \").strip()\n",
    "\n",
    "        if img_path.lower() == 'quit':\n",
    "            break\n",
    "\n",
    "        result = predict_cluster_for_image(img_path)\n",
    "\n",
    "        if result is None:\n",
    "            print(f\"Could not predict for: {img_path}\\n\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nPredicted Cluster: {result['cluster']}\")\n",
    "        print(f\"Predicted Type: {result['cluster_label']}\")\n",
    "        print(f\"Distance to Cluster 0: {result['distances'].get(0, float('nan')):.4f}\")\n",
    "        print(f\"Distance to Cluster 1: {result['distances'].get(1, float('nan')):.4f}\")\n",
    "        print()\n",
    "\n",
    "# Note: Do NOT call run_interactive_prompt() automatically in this notebook. To use interactive mode,\n",
    "# run `run_interactive_prompt()` in a cell when you want to interact with the model. For non-interactive\n",
    "# uses, call `predict_cluster_for_image(path)` directly (works for scripts and batch processing)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
